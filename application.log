2025-08-18 15:00:19,611 - root - INFO - i am in the main method
2025-08-18 15:00:19,611 - root - INFO - calling spark object
2025-08-18 15:00:19,611 - Create_spark - INFO - get_spark_object method started
2025-08-18 15:00:19,611 - Create_spark - INFO - master is local
2025-08-18 15:00:36,024 - Create_spark - INFO - Spark object created ...
2025-08-18 15:00:36,024 - root - INFO - Validating spark object...
2025-08-18 15:00:36,026 - Validate - WARNING - started the get_current_date method...
2025-08-18 15:00:39,908 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 15:00:39,908 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 15:00:39,908 - root - INFO - Application done
2025-08-18 15:34:01,483 - root - INFO - i am in the main method
2025-08-18 15:34:01,483 - root - INFO - calling spark object
2025-08-18 15:34:01,483 - Create_spark - INFO - get_spark_object method started
2025-08-18 15:34:01,483 - Create_spark - INFO - master is local
2025-08-18 15:34:06,234 - Create_spark - INFO - Spark object created ...
2025-08-18 15:34:06,234 - root - INFO - Validating spark object...
2025-08-18 15:34:06,234 - Validate - WARNING - started the get_current_date method...
2025-08-18 15:34:09,980 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 15:34:09,980 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 15:34:09,980 - root - INFO - Application done
2025-08-18 15:37:16,891 - root - INFO - i am in the main method
2025-08-18 15:37:16,891 - root - INFO - calling spark object
2025-08-18 15:37:16,891 - Create_spark - INFO - get_spark_object method started
2025-08-18 15:37:16,891 - Create_spark - INFO - master is local
2025-08-18 15:37:21,577 - Create_spark - INFO - Spark object created ...
2025-08-18 15:37:21,577 - root - INFO - Validating spark object...
2025-08-18 15:37:21,577 - Validate - WARNING - started the get_current_date method...
2025-08-18 15:37:25,427 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 15:37:25,427 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 15:37:25,427 - root - INFO - Application done
2025-08-18 15:39:34,152 - root - INFO - i am in the main method
2025-08-18 15:39:34,153 - root - INFO - calling spark object
2025-08-18 15:39:34,153 - Create_spark - INFO - get_spark_object method started
2025-08-18 15:39:34,153 - Create_spark - INFO - master is local
2025-08-18 15:39:38,774 - Create_spark - INFO - Spark object created ...
2025-08-18 15:39:38,775 - root - INFO - Validating spark object...
2025-08-18 15:39:38,775 - Validate - WARNING - started the get_current_date method...
2025-08-18 15:39:42,398 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 15:39:42,398 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 15:39:42,398 - root - INFO - Application done
2025-08-18 16:13:03,188 - root - INFO - i am in the main method
2025-08-18 16:13:03,188 - root - INFO - calling spark object
2025-08-18 16:13:03,188 - Create_spark - INFO - get_spark_object method started
2025-08-18 16:13:03,188 - Create_spark - INFO - master is local
2025-08-18 16:13:07,953 - Create_spark - INFO - Spark object created ...
2025-08-18 16:13:07,953 - root - INFO - Validating spark object...
2025-08-18 16:13:07,953 - Validate - WARNING - started the get_current_date method...
2025-08-18 16:13:12,229 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 16:13:12,229 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 16:13:12,230 - root - INFO - reading file which is of > parquet 
2025-08-18 16:13:12,230 - Ingest - WARNING - load_files method started...
2025-08-18 16:13:12,924 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 16:13:12,928 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 16:13:15,262 - root - INFO - Application done
2025-08-18 16:41:20,998 - root - INFO - i am in the main method
2025-08-18 16:41:20,998 - root - INFO - calling spark object
2025-08-18 16:41:20,999 - Create_spark - INFO - get_spark_object method started
2025-08-18 16:41:20,999 - Create_spark - INFO - master is local
2025-08-18 16:41:25,463 - Create_spark - INFO - Spark object created ...
2025-08-18 16:41:25,463 - root - INFO - Validating spark object...
2025-08-18 16:41:25,463 - Validate - WARNING - started the get_current_date method...
2025-08-18 16:41:29,146 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 16:41:29,146 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 16:41:29,147 - root - INFO - reading file which is of > parquet 
2025-08-18 16:41:29,147 - Ingest - WARNING - load_files method started...
2025-08-18 16:41:29,723 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 16:41:29,726 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 16:41:31,559 - root - INFO - validating the dataframe...
2025-08-18 16:41:31,559 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 16:41:32,159 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2025-08-18 16:41:32,159 - root - INFO - Application done
2025-08-18 20:19:47,704 - root - INFO - i am in the main method
2025-08-18 20:19:47,705 - root - INFO - calling spark object
2025-08-18 20:19:47,705 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:19:47,705 - Create_spark - INFO - master is local
2025-08-18 20:19:54,220 - Create_spark - INFO - Spark object created ...
2025-08-18 20:19:54,220 - root - INFO - Validating spark object...
2025-08-18 20:19:54,220 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:19:59,476 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:19:59,476 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:19:59,476 - root - INFO - reading file which is of > csv 
2025-08-18 20:19:59,476 - Ingest - WARNING - load_files method started...
2025-08-18 20:25:20,051 - root - INFO - i am in the main method
2025-08-18 20:25:20,051 - root - INFO - calling spark object
2025-08-18 20:25:20,051 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:25:20,051 - Create_spark - INFO - master is local
2025-08-18 20:25:24,836 - Create_spark - INFO - Spark object created ...
2025-08-18 20:25:24,836 - root - INFO - Validating spark object...
2025-08-18 20:25:24,836 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:25:28,823 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:25:28,823 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:25:28,823 - root - INFO - reading file which is of > parquet 
2025-08-18 20:25:28,823 - Ingest - WARNING - load_files method started...
2025-08-18 20:25:29,579 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:25:29,583 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:25:31,578 - root - INFO - validating the dataframe...
2025-08-18 20:25:31,578 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:25:32,153 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2025-08-18 20:25:32,153 - Ingest - WARNING - load_files method started...
2025-08-18 20:26:35,606 - root - INFO - i am in the main method
2025-08-18 20:26:35,606 - root - INFO - calling spark object
2025-08-18 20:26:35,606 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:26:35,606 - Create_spark - INFO - master is local
2025-08-18 20:26:40,279 - Create_spark - INFO - Spark object created ...
2025-08-18 20:26:40,279 - root - INFO - Validating spark object...
2025-08-18 20:26:40,279 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:26:44,174 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:26:44,174 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:26:44,174 - root - INFO - reading file which is of > parquet 
2025-08-18 20:26:44,174 - Ingest - WARNING - load_files method started...
2025-08-18 20:26:44,903 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:26:44,908 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:26:47,007 - root - INFO - validating the dataframe...
2025-08-18 20:26:47,007 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:26:47,715 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2025-08-18 20:26:47,715 - Ingest - WARNING - load_files method started...
2025-08-18 20:29:16,808 - root - INFO - i am in the main method
2025-08-18 20:29:16,809 - root - INFO - calling spark object
2025-08-18 20:29:16,809 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:29:16,809 - Create_spark - INFO - master is local
2025-08-18 20:29:21,339 - Create_spark - INFO - Spark object created ...
2025-08-18 20:29:21,339 - root - INFO - Validating spark object...
2025-08-18 20:29:21,339 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:29:24,930 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:29:24,930 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:29:24,931 - root - INFO - reading file which is of > parquet 
2025-08-18 20:29:24,931 - Ingest - WARNING - load_files method started...
2025-08-18 20:29:25,513 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:29:25,517 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:29:27,530 - root - INFO - validating the dataframe...
2025-08-18 20:29:27,530 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:29:28,069 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2025-08-18 20:29:28,069 - Ingest - WARNING - load_files method started...
2025-08-18 20:31:45,649 - root - INFO - i am in the main method
2025-08-18 20:31:45,650 - root - INFO - calling spark object
2025-08-18 20:31:45,650 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:31:45,650 - Create_spark - INFO - master is local
2025-08-18 20:31:50,339 - Create_spark - INFO - Spark object created ...
2025-08-18 20:31:50,339 - root - INFO - Validating spark object...
2025-08-18 20:31:50,339 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:31:54,134 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:31:54,134 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:31:54,134 - root - INFO - reading file which is of > parquet 
2025-08-18 20:31:54,135 - Ingest - WARNING - load_files method started...
2025-08-18 20:31:54,744 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:31:54,748 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:31:56,511 - root - INFO - validating the dataframe...
2025-08-18 20:31:56,511 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:31:57,067 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2025-08-18 20:31:57,067 - Ingest - WARNING - load_files method started...
2025-08-18 20:33:53,185 - root - INFO - i am in the main method
2025-08-18 20:33:53,185 - root - INFO - calling spark object
2025-08-18 20:33:53,185 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:33:53,185 - Create_spark - INFO - master is local
2025-08-18 20:33:57,429 - Create_spark - INFO - Spark object created ...
2025-08-18 20:33:57,429 - root - INFO - Validating spark object...
2025-08-18 20:33:57,429 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:34:01,307 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:34:01,307 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:34:01,307 - root - INFO - reading file which is of > parquet 
2025-08-18 20:34:01,307 - Ingest - WARNING - load_files method started...
2025-08-18 20:34:01,955 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:34:01,961 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:34:03,857 - root - INFO - validating the dataframe...
2025-08-18 20:34:03,857 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:34:04,364 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 20:34:04,365 - Ingest - WARNING - load_files method started...
2025-08-18 20:34:04,524 - Ingest - ERROR - An error occured at load_files===[PATH_NOT_FOUND] Path does not exist: file:/E:/data-projects/pysparkProject/source/olap/USA_Presc_Medicare_Data_12021.csv.
2025-08-18 20:35:45,292 - root - INFO - i am in the main method
2025-08-18 20:35:45,292 - root - INFO - calling spark object
2025-08-18 20:35:45,293 - Create_spark - INFO - get_spark_object method started
2025-08-18 20:35:45,293 - Create_spark - INFO - master is local
2025-08-18 20:35:49,473 - Create_spark - INFO - Spark object created ...
2025-08-18 20:35:49,473 - root - INFO - Validating spark object...
2025-08-18 20:35:49,474 - Validate - WARNING - started the get_current_date method...
2025-08-18 20:35:53,036 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 20:35:53,036 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 20:35:53,036 - root - INFO - reading file which is of > parquet 
2025-08-18 20:35:53,036 - Ingest - WARNING - load_files method started...
2025-08-18 20:35:53,579 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 20:35:53,582 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 20:35:55,327 - root - INFO - validating the dataframe...
2025-08-18 20:35:55,327 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 20:35:55,848 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 20:35:55,848 - Ingest - WARNING - load_files method started...
2025-08-18 20:35:59,890 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 20:35:59,893 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 20:36:00,115 - root - INFO - validating the dataframe...
2025-08-18 20:36:00,115 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 20:36:00,780 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 20:36:00,780 - root - INFO - Application done
2025-08-18 21:24:09,958 - root - INFO - i am in the main method
2025-08-18 21:24:09,959 - root - INFO - calling spark object
2025-08-18 21:24:09,959 - Create_spark - INFO - get_spark_object method started
2025-08-18 21:24:09,959 - Create_spark - INFO - master is local
2025-08-18 21:24:14,941 - Create_spark - INFO - Spark object created ...
2025-08-18 21:24:14,941 - root - INFO - Validating spark object...
2025-08-18 21:24:14,941 - Validate - WARNING - started the get_current_date method...
2025-08-18 21:24:19,001 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 21:24:19,001 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 21:24:19,001 - root - INFO - reading file which is of > parquet 
2025-08-18 21:24:19,001 - Ingest - WARNING - load_files method started...
2025-08-18 21:24:19,643 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 21:24:19,646 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 21:24:21,608 - root - INFO - validating the dataframe...
2025-08-18 21:24:21,608 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 21:24:22,181 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 21:24:22,182 - Ingest - WARNING - load_files method started...
2025-08-18 21:24:26,670 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 21:24:26,672 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 21:24:26,909 - root - INFO - validating the dataframe...
2025-08-18 21:24:26,909 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 21:24:27,704 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 21:24:27,704 - root - INFO - Application done
2025-08-18 22:17:47,627 - root - INFO - i am in the main method
2025-08-18 22:17:47,627 - root - INFO - calling spark object
2025-08-18 22:17:47,627 - Create_spark - INFO - get_spark_object method started
2025-08-18 22:17:47,627 - Create_spark - INFO - master is local
2025-08-18 22:17:52,315 - Create_spark - INFO - Spark object created ...
2025-08-18 22:17:52,315 - root - INFO - Validating spark object...
2025-08-18 22:17:52,315 - Validate - WARNING - started the get_current_date method...
2025-08-18 22:17:56,067 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 22:17:56,067 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 22:17:56,068 - root - INFO - reading file which is of > parquet 
2025-08-18 22:17:56,068 - Ingest - WARNING - load_files method started...
2025-08-18 22:17:56,685 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 22:17:56,689 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 22:17:58,433 - root - INFO - validating the dataframe...
2025-08-18 22:17:58,433 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 22:17:58,960 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 22:17:58,961 - Ingest - WARNING - load_files method started...
2025-08-18 22:18:02,712 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 22:18:02,715 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 22:18:02,926 - root - INFO - validating the dataframe...
2025-08-18 22:18:02,926 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 22:18:03,613 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 22:18:03,613 - root - INFO - implementing data_processing methods...
2025-08-18 22:18:03,613 - Data_processing - WARNING - data_clean method() started...
2025-08-18 22:18:03,614 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-18 22:18:03,654 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-18 22:18:03,672 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-18 22:18:03,960 - root - INFO - Application done
2025-08-18 22:25:31,860 - root - INFO - i am in the main method
2025-08-18 22:25:31,860 - root - INFO - calling spark object
2025-08-18 22:25:31,861 - Create_spark - INFO - get_spark_object method started
2025-08-18 22:25:31,861 - Create_spark - INFO - master is local
2025-08-18 22:25:36,006 - Create_spark - INFO - Spark object created ...
2025-08-18 22:25:36,006 - root - INFO - Validating spark object...
2025-08-18 22:25:36,006 - Validate - WARNING - started the get_current_date method...
2025-08-18 22:25:39,675 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 22:25:39,675 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 22:25:39,675 - root - INFO - reading file which is of > parquet 
2025-08-18 22:25:39,675 - Ingest - WARNING - load_files method started...
2025-08-18 22:25:40,324 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 22:25:40,329 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 22:25:42,074 - root - INFO - validating the dataframe...
2025-08-18 22:25:42,074 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 22:25:42,569 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 22:25:42,570 - Ingest - WARNING - load_files method started...
2025-08-18 22:25:46,558 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 22:25:46,560 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 22:25:46,765 - root - INFO - validating the dataframe...
2025-08-18 22:25:46,765 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 22:25:47,477 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 22:25:47,477 - root - INFO - implementing data_processing methods...
2025-08-18 22:25:47,477 - Data_processing - WARNING - data_clean method() started...
2025-08-18 22:25:47,477 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-18 22:25:47,514 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-18 22:25:47,532 - Data_processing - WARNING - Adding a new column to df_presc_sel
2025-08-18 22:25:47,543 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-18 22:25:47,851 - root - INFO - Application done
2025-08-18 22:36:00,885 - root - INFO - i am in the main method
2025-08-18 22:36:00,885 - root - INFO - calling spark object
2025-08-18 22:36:00,885 - Create_spark - INFO - get_spark_object method started
2025-08-18 22:36:00,885 - Create_spark - INFO - master is local
2025-08-18 22:36:05,175 - Create_spark - INFO - Spark object created ...
2025-08-18 22:36:05,176 - root - INFO - Validating spark object...
2025-08-18 22:36:05,176 - Validate - WARNING - started the get_current_date method...
2025-08-18 22:36:08,916 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 22:36:08,916 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 22:36:08,917 - root - INFO - reading file which is of > parquet 
2025-08-18 22:36:08,917 - Ingest - WARNING - load_files method started...
2025-08-18 22:36:09,470 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 22:36:09,475 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 22:36:11,188 - root - INFO - validating the dataframe...
2025-08-18 22:36:11,188 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 22:36:11,757 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 22:36:11,757 - Ingest - WARNING - load_files method started...
2025-08-18 22:36:15,764 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 22:36:15,766 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 22:36:16,046 - root - INFO - validating the dataframe...
2025-08-18 22:36:16,046 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 22:36:17,017 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 22:36:17,017 - root - INFO - implementing data_processing methods...
2025-08-18 22:36:17,017 - Data_processing - WARNING - data_clean method() started...
2025-08-18 22:36:17,017 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-18 22:36:17,055 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-18 22:36:17,068 - Data_processing - WARNING - Adding a new column to df_presc_sel
2025-08-18 22:36:17,078 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-18 22:36:17,422 - root - INFO - validating schema for the dataframes...
2025-08-18 22:36:17,422 - Validate - WARNING - print schema method executing ...df_city_sel
2025-08-18 22:36:17,424 - Validate - INFO - 	StructField('city', StringType(), True)
2025-08-18 22:36:17,424 - Validate - INFO - 	StructField('state_id', StringType(), True)
2025-08-18 22:36:17,424 - Validate - INFO - 	StructField('state_name', StringType(), True)
2025-08-18 22:36:17,424 - Validate - INFO - 	StructField('county_name', StringType(), True)
2025-08-18 22:36:17,425 - Validate - INFO - 	StructField('population', IntegerType(), True)
2025-08-18 22:36:17,425 - Validate - INFO - 	StructField('zips', StringType(), True)
2025-08-18 22:36:17,425 - Validate - INFO - print_schema done, go frwd...
2025-08-18 22:36:17,425 - Validate - WARNING - print schema method executing ...df_presc_sel
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_lname', StringType(), True)
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_fname', StringType(), True)
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2025-08-18 22:36:17,426 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('years_of_exp', StringType(), True)
2025-08-18 22:36:17,427 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2025-08-18 22:36:17,427 - Validate - INFO - print_schema done, go frwd...
2025-08-18 22:36:17,427 - root - INFO - Application done
2025-08-18 23:03:19,901 - root - INFO - i am in the main method
2025-08-18 23:03:19,901 - root - INFO - calling spark object
2025-08-18 23:03:19,901 - Create_spark - INFO - get_spark_object method started
2025-08-18 23:03:19,901 - Create_spark - INFO - master is local
2025-08-18 23:03:36,765 - Create_spark - INFO - Spark object created ...
2025-08-18 23:03:36,766 - root - INFO - Validating spark object...
2025-08-18 23:03:36,766 - Validate - WARNING - started the get_current_date method...
2025-08-18 23:03:40,445 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 23:03:40,445 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 23:03:40,446 - root - INFO - reading file which is of > parquet 
2025-08-18 23:03:40,446 - Ingest - WARNING - load_files method started...
2025-08-18 23:03:41,005 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 23:03:41,009 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 23:03:42,814 - root - INFO - validating the dataframe...
2025-08-18 23:03:42,814 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 23:03:43,360 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 23:45:15,520 - root - INFO - i am in the main method
2025-08-18 23:45:15,521 - root - INFO - calling spark object
2025-08-18 23:45:15,521 - Create_spark - INFO - get_spark_object method started
2025-08-18 23:45:15,521 - Create_spark - INFO - master is local
2025-08-18 23:45:19,601 - Create_spark - INFO - Spark object created ...
2025-08-18 23:45:19,601 - root - INFO - Validating spark object...
2025-08-18 23:45:19,601 - Validate - WARNING - started the get_current_date method...
2025-08-18 23:45:22,841 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 23:45:22,841 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 23:45:22,841 - root - INFO - reading file which is of > parquet 
2025-08-18 23:45:22,841 - Ingest - WARNING - load_files method started...
2025-08-18 23:45:23,368 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 23:45:23,372 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 23:45:24,975 - root - INFO - validating the dataframe...
2025-08-18 23:45:24,975 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 23:45:25,466 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 23:45:25,466 - Ingest - WARNING - load_files method started...
2025-08-18 23:45:29,390 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 23:45:29,393 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 23:45:29,582 - root - INFO - validating the dataframe...
2025-08-18 23:45:29,582 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 23:45:30,224 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 23:45:30,224 - root - INFO - implementing data_processing methods...
2025-08-18 23:45:30,224 - Data_processing - WARNING - data_clean method() started...
2025-08-18 23:45:30,224 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-18 23:45:30,256 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-18 23:45:30,273 - Data_processing - WARNING - Adding a new column to df_presc_sel
2025-08-18 23:45:30,282 - Data_processing - WARNING - converting Year_of_exp string to Int and replacing = 
2025-08-18 23:45:30,312 - Data_processing - WARNING - concat first and lname
2025-08-18 23:45:30,330 - Data_processing - WARNING - now dropping presc_lname and presc_fname
2025-08-18 23:45:30,339 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-18 23:45:30,636 - root - INFO - validating schema for the dataframes...
2025-08-18 23:45:30,636 - Validate - WARNING - print schema method executing ...df_city_sel
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('city', StringType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('state_id', StringType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('state_name', StringType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('county_name', StringType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('population', IntegerType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - 	StructField('zips', StringType(), True)
2025-08-18 23:45:30,637 - Validate - INFO - print_schema done, go frwd...
2025-08-18 23:45:30,637 - Validate - WARNING - print schema method executing ...df_presc_sel
2025-08-18 23:45:30,638 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2025-08-18 23:45:30,639 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2025-08-18 23:45:30,639 - Validate - INFO - print_schema done, go frwd...
2025-08-18 23:45:30,639 - root - INFO - Application done
2025-08-18 23:51:27,574 - root - INFO - i am in the main method
2025-08-18 23:51:27,575 - root - INFO - calling spark object
2025-08-18 23:51:27,575 - Create_spark - INFO - get_spark_object method started
2025-08-18 23:51:27,575 - Create_spark - INFO - master is local
2025-08-18 23:51:32,310 - Create_spark - INFO - Spark object created ...
2025-08-18 23:51:32,310 - root - INFO - Validating spark object...
2025-08-18 23:51:32,310 - Validate - WARNING - started the get_current_date method...
2025-08-18 23:51:36,435 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 18))]
2025-08-18 23:51:36,435 - Validate - WARNING - Validation done, go frwd... 
2025-08-18 23:51:36,436 - root - INFO - reading file which is of > parquet 
2025-08-18 23:51:36,436 - Ingest - WARNING - load_files method started...
2025-08-18 23:51:37,002 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-18 23:51:37,007 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-18 23:51:38,802 - root - INFO - validating the dataframe...
2025-08-18 23:51:38,802 - Ingest - WARNING - here to count the records in the df_city
2025-08-18 23:51:39,310 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-18 23:51:39,311 - Ingest - WARNING - load_files method started...
2025-08-18 23:51:43,359 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-18 23:51:43,361 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-18 23:51:43,587 - root - INFO - validating the dataframe...
2025-08-18 23:51:43,587 - Ingest - WARNING - here to count the records in the df_fact
2025-08-18 23:51:44,297 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-18 23:51:44,297 - root - INFO - implementing data_processing methods...
2025-08-18 23:51:44,297 - Data_processing - WARNING - data_clean method() started...
2025-08-18 23:51:44,297 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-18 23:51:44,334 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-18 23:51:44,348 - Data_processing - WARNING - Adding a new column to df_presc_sel
2025-08-18 23:51:44,360 - Data_processing - WARNING - converting Year_of_exp string to Int and replacing = 
2025-08-18 23:51:44,394 - Data_processing - WARNING - concat first and lname
2025-08-18 23:51:44,413 - Data_processing - WARNING - now dropping presc_lname and presc_fname
2025-08-18 23:51:44,423 - Data_processing - WARNING - check for null values in all columns
2025-08-18 23:51:44,568 - Data_processing - WARNING - drop the null values in the respective columns
2025-08-18 23:51:44,569 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-18 23:52:01,545 - root - INFO - validating schema for the dataframes...
2025-08-18 23:52:01,545 - Validate - WARNING - print schema method executing ...df_city_sel
2025-08-18 23:52:01,546 - Validate - INFO - 	StructField('city', StringType(), True)
2025-08-18 23:52:01,546 - Validate - INFO - 	StructField('state_id', StringType(), True)
2025-08-18 23:52:01,546 - Validate - INFO - 	StructField('state_name', StringType(), True)
2025-08-18 23:52:01,546 - Validate - INFO - 	StructField('county_name', StringType(), True)
2025-08-18 23:52:01,546 - Validate - INFO - 	StructField('population', IntegerType(), True)
2025-08-18 23:52:01,547 - Validate - INFO - 	StructField('zips', StringType(), True)
2025-08-18 23:52:01,547 - Validate - INFO - print_schema done, go frwd...
2025-08-18 23:52:01,547 - Validate - WARNING - print schema method executing ...df_presc_sel
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2025-08-18 23:52:01,548 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2025-08-18 23:52:01,549 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2025-08-18 23:52:01,549 - Validate - INFO - print_schema done, go frwd...
2025-08-18 23:52:01,549 - root - INFO - Application done
2025-08-19 00:06:42,152 - root - INFO - i am in the main method
2025-08-19 00:06:42,152 - root - INFO - calling spark object
2025-08-19 00:06:42,152 - Create_spark - INFO - get_spark_object method started
2025-08-19 00:06:42,152 - Create_spark - INFO - master is local
2025-08-19 00:06:46,126 - Create_spark - INFO - Spark object created ...
2025-08-19 00:06:46,126 - root - INFO - Validating spark object...
2025-08-19 00:06:46,126 - Validate - WARNING - started the get_current_date method...
2025-08-19 00:06:50,087 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 19))]
2025-08-19 00:06:50,087 - Validate - WARNING - Validation done, go frwd... 
2025-08-19 00:06:50,087 - root - INFO - reading file which is of > parquet 
2025-08-19 00:06:50,087 - Ingest - WARNING - load_files method started...
2025-08-19 00:06:50,784 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-19 00:06:50,792 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-19 00:06:52,635 - root - INFO - validating the dataframe...
2025-08-19 00:06:52,635 - Ingest - WARNING - here to count the records in the df_city
2025-08-19 00:06:53,141 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-19 00:06:53,141 - Ingest - WARNING - load_files method started...
2025-08-19 00:06:53,334 - Ingest - ERROR - An error occured at load_files===[UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually.
2025-08-19 00:08:03,666 - root - INFO - i am in the main method
2025-08-19 00:08:03,666 - root - INFO - calling spark object
2025-08-19 00:08:03,666 - Create_spark - INFO - get_spark_object method started
2025-08-19 00:08:03,666 - Create_spark - INFO - master is local
2025-08-19 00:08:08,082 - Create_spark - INFO - Spark object created ...
2025-08-19 00:08:08,082 - root - INFO - Validating spark object...
2025-08-19 00:08:08,082 - Validate - WARNING - started the get_current_date method...
2025-08-19 00:08:11,678 - Validate - WARNING - validating spark object with current date -[Row(current_date()=datetime.date(2025, 8, 19))]
2025-08-19 00:08:11,679 - Validate - WARNING - Validation done, go frwd... 
2025-08-19 00:08:11,679 - root - INFO - reading file which is of > parquet 
2025-08-19 00:08:11,679 - Ingest - WARNING - load_files method started...
2025-08-19 00:08:12,248 - Ingest - WARNING - dataframe created successfully which is of parquet
2025-08-19 00:08:12,252 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2025-08-19 00:08:14,028 - root - INFO - validating the dataframe...
2025-08-19 00:08:14,028 - Ingest - WARNING - here to count the records in the df_city
2025-08-19 00:08:14,530 - Ingest - WARNING - Number of records present in the df_city are :: 28338 
2025-08-19 00:08:14,530 - Ingest - WARNING - load_files method started...
2025-08-19 00:08:18,560 - Ingest - WARNING - dataframe created successfully which is of csv
2025-08-19 00:08:18,563 - root - INFO - display the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2025-08-19 00:08:18,747 - root - INFO - validating the dataframe...
2025-08-19 00:08:18,747 - Ingest - WARNING - here to count the records in the df_fact
2025-08-19 00:08:19,432 - Ingest - WARNING - Number of records present in the df_fact are :: 1329329 
2025-08-19 00:08:19,432 - root - INFO - implementing data_processing methods...
2025-08-19 00:08:19,433 - Data_processing - WARNING - data_clean method() started...
2025-08-19 00:08:19,433 - Data_processing - WARNING - select required columns and converting some of columns into upper case..
2025-08-19 00:08:19,464 - Data_processing - WARNING - working on OLTP dataset and selecting couple of  columns and rename...
2025-08-19 00:08:19,477 - Data_processing - WARNING - Adding a new column to df_presc_sel
2025-08-19 00:08:19,485 - Data_processing - WARNING - converting Year_of_exp string to Int and replacing = 
2025-08-19 00:08:19,517 - Data_processing - WARNING - concat first and lname
2025-08-19 00:08:19,536 - Data_processing - WARNING - now dropping presc_lname and presc_fname
2025-08-19 00:08:19,544 - Data_processing - WARNING - check for null values in all columns
2025-08-19 00:08:19,665 - Data_processing - WARNING - drop the null values in the respective columns
2025-08-19 00:08:19,688 - Data_processing - WARNING - successfully droped the null values... 
2025-08-19 00:08:19,688 - Data_processing - WARNING - data_clean() method executed done, go frwd...
2025-08-19 00:08:37,219 - root - INFO - validating schema for the dataframes...
2025-08-19 00:08:37,219 - Validate - WARNING - print schema method executing ...df_city_sel
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('city', StringType(), True)
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('state_id', StringType(), True)
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('state_name', StringType(), True)
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('county_name', StringType(), True)
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('population', IntegerType(), True)
2025-08-19 00:08:37,221 - Validate - INFO - 	StructField('zips', StringType(), True)
2025-08-19 00:08:37,222 - Validate - INFO - print_schema done, go frwd...
2025-08-19 00:08:37,222 - Validate - WARNING - print schema method executing ...df_presc_sel
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2025-08-19 00:08:37,223 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2025-08-19 00:08:37,224 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2025-08-19 00:08:37,224 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2025-08-19 00:08:37,224 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2025-08-19 00:08:37,224 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2025-08-19 00:08:37,224 - Validate - INFO - print_schema done, go frwd...
2025-08-19 00:08:37,224 - root - INFO - Application done
